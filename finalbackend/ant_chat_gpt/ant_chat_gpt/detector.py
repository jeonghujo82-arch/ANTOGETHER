import os
import re
import json
from datetime import datetime
from openai import OpenAI
from dotenv import load_dotenv

# .env ê²½ë¡œ ë¡œë“œ
# Environment variables are now loaded globally in backend_new.py

# âœ… ì‹¤ì œ êµ¬í˜„ëœ NewsScheduleExtractor ì‚¬ìš©
from .gpt_search.naver_text_extract import NewsScheduleExtractor


class GPTDateDetector:
    """
    GPTë¥¼ ì‚¬ìš©í•´ ë©”ì‹œì§€ì— ë‚ ì§œ ê´€ë ¨ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” í´ë˜ìŠ¤.
    ì¼ì • í¬í•¨ ì—¬ë¶€ (True/False)ì™€ í† í° ì‚¬ìš©ëŸ‰ì„ ë°˜í™˜í•˜ë©°,
    ì¼ì •ì´ ì—†ì„ ê²½ìš° ì¼ë°˜ ëŒ€í™” ë‹µë³€ë„ ìƒì„±í•  ìˆ˜ ìˆìŒ.
    """
    def __init__(self, model="gpt-4o-mini"):
        self.model = model
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.conversation_history = []
        self.crawlr = NewsScheduleExtractor(model=model)

    def has_date(self, message: str) -> tuple[bool, dict]:
        today = datetime.now().strftime("%Y-%m-%d")
        prompt = f"""
ì•„ë˜ ë¬¸ì¥ì— 'ì¼ì •ì„ ìƒì„±í•˜ë ¤ëŠ” ì˜ë„'ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ë§Œ íŒë‹¨í•´ì£¼ì„¸ìš”.
'ì½˜ì„œíŠ¸ ì¼ì • ì•Œë ¤ì¤˜'ì²˜ëŸ¼ ë¬´ì–¸ê°€ë¥¼ í•˜ë ¤ëŠ” ê³„íš, ìš”ì²­, ì˜ì§€ê°€ ìˆë‹¤ë©´ 'true'ë¥¼,
ë‹¨ìˆœí•œ ì¸ì‚¬ë‚˜ ê³¼ê±° íšŒìƒ, ì •ë³´ ìš”ì²­ì´ ì•„ë‹ˆë¼ë©´ 'false'ë¥¼ ì¶œë ¥í•˜ì„¸ìš”.

ì˜ˆë¥¼ ë“¤ì–´ ë‹¤ìŒ ë¬¸ì¥ë“¤ì€ ëª¨ë‘ 'true'ë¡œ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤:
- í”Œë ˆì´ë¸Œ ì½˜ì„œíŠ¸ ì–¸ì œ í•´?
- BTS ì½˜ì„œíŠ¸ ì¼ì • ì•Œë ¤ì¤˜
- ì˜¤ì•„ì‹œìŠ¤ ë‚´í•œ ì¼ì • ì•Œë ¤ì¤˜
- ë‚´ì¼ íšŒì˜ ìˆì–´
- 3ì›” 2ì¼ì— ë¯¸íŒ… ì¡í˜”ì–´
- ë‹¤ìŒì£¼ ê¸ˆìš”ì¼ì— ì•½ì† ìˆìŒ

ë‹¨ìˆœí•œ ì¸ì‚¬ë§ì´ë‚˜, ì¼ì •ê³¼ ë¬´ê´€í•œ ë¬¸ì¥ì€ 'false'ë¡œ íŒë‹¨í•´ì•¼ í•©ë‹ˆë‹¤:
- ì•ˆë…•, ì˜ ì§€ë‚´?
- ë‚˜ëŠ” ì˜¤ëŠ˜ í”¼ê³¤í•´

ë‚ ì§œ ì •ë³´(ì˜ˆ: ì˜¤ëŠ˜, ë‚´ì¼)ê°€ ì—†ì–´ë„ ì¼ì • ìƒì„± ì˜ë„ê°€ ìˆìœ¼ë©´ 'true'ë¡œ íŒë‹¨í•˜ì„¸ìš”.
ì •í™•íˆ 'true' ë˜ëŠ” 'false'ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ë¬¸ì¥: "{message}"
"""

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¼ì • ìƒì„± ì˜ë„ë¥¼ íŒë³„í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì˜¤ì§ true ë˜ëŠ” falseë§Œ ë°˜í™˜í•˜ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0,
        )

        answer = response.choices[0].message.content.strip().lower()
        usage = response.usage.model_dump()

        if "true" in answer:
            return True, usage
        else:
            print(f"[GPT ì‘ë‹µ] {message} â†’ ì¼ì • ì •ë³´ ì—†ìŒ ğŸ‘‹nâš ï¸ GPT íŒë‹¨ ê²°ê³¼: {answer}")
            return False, usage

    def has_date_info(self, message: str) -> tuple[bool, dict]:
        today = datetime.now().strftime("%Y-%m-%d")

        prompt = f"""
ë‹¤ìŒ ë¬¸ì¥ì— ì‹¤ì œë¡œ 'ì¼ì •ìœ¼ë¡œ ë“±ë¡ ê°€ëŠ¥í•œ ì •ë³´'ê°€ ë‹´ê²¨ ìˆëŠ”ì§€ íŒë‹¨í•´ì£¼ì„¸ìš”.

ì¼ì •ìœ¼ë¡œ ë“±ë¡ ê°€ëŠ¥í•œ ì •ë³´ë€ ë‹¤ìŒ ë‘ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:
1. ì‚¬ìš©ìê°€ ì–´ë–¤ í™œë™ì„ í•˜ê² ë‹¤ëŠ” ì˜ë„ ë˜ëŠ” ê³„íšì´ ë“œëŸ¬ë‚˜ ìˆì–´ì•¼ í•¨
2. ë‚ ì§œ ë˜ëŠ” ì‹œê°„ ì •ë³´ê°€ êµ¬ì²´ì ìœ¼ë¡œ í‘œí˜„ë˜ì–´ ìˆì–´ì•¼ í•¨ (ì˜ˆ: ë‚´ì¼, 3ì›” 2ì¼, ì˜¤í›„ 5ì‹œ ë“±)

ì˜ˆì‹œ (true):
- ë‚´ì¼ íšŒì˜ ìˆì–´
- 3ì›” 2ì¼ ì €ë…ì— ì•½ì† ìˆìŒ
- ì˜¤ëŠ˜ ì˜¤í›„ 2ì‹œì— ì „í™”í•˜ì
- ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼ì— íšŒì‹ ìˆìŒ

ì˜ˆì‹œ (false):
- ë‹¤ìŒì£¼ì— ë­ í• ê¹Œ?
- ë‚˜ì¤‘ì— ë³´ì
- ì´ë²ˆ ì£¼ëŠ” ë°”ë¹ 
- ì‹œê°„ ì •í•´ì„œ ë§Œë‚˜ì

ì˜¤ëŠ˜ ë‚ ì§œëŠ” {today}ì…ë‹ˆë‹¤.

ì¶œë ¥ì€ ì •í™•íˆ ì†Œë¬¸ìë¡œ true ë˜ëŠ” false ì¤‘ í•˜ë‚˜ë§Œ ì‘ì„±í•˜ì„¸ìš”.  
ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ë§ˆì¹¨í‘œ, ê³µë°± ì—†ì´ **ì˜¤ì§ ë‹¨ì–´ë§Œ ì¶œë ¥**í•´ì•¼ í•©ë‹ˆë‹¤.

ë¬¸ì¥: "{message}"
"""

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
        )

        reply = response.choices[0].message.content.strip().lower()
        has_date = reply.startswith("true")
        usage = response.usage.to_dict() if hasattr(response, "usage") else {}

        return has_date, usage

    def _clean_json_output(self, text: str) -> str:
        text = text.strip()
        text = re.sub(r"^```json", "", text)
        text = re.sub(r"```$", "", text)
        return text.strip()

    def extract_schedule(self, message: str) -> tuple[dict, dict]:
        today = datetime.now().strftime("%Y-%m-%d")

        prompt = f"""
ì•„ë˜ ë¬¸ì¥ì—ì„œ ì¼ì •ì„ ì¶”ì¶œí•´ì„œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”.

---
í˜•ì‹:
{{
  "events": [
    {{
      "start_date": "YYYY-MM-DD-HH:mm",
      "end_date": "YYYY-MM-DD-HH:mm",
      "title": "ì¼ì • ë‚´ìš©"
    }}
  ]
}}
---

ì¡°ê±´:
- "~ë¶€í„°", "~ê¹Œì§€" ë“±ì˜ í‘œí˜„ì€ start_date, end_dateë¡œ ë¶„ë¦¬
- "~ì˜ˆì •", "~í•˜ì", "~í•  ê±°ì•¼" ë“±ì˜ ë¬¸ì¥ì€ eventë¡œ ê°„ì£¼
- start_dateì™€ end_dateëŠ” ë™ì¼í•´ë„ í—ˆìš©
- "ì˜¤ëŠ˜", "ë‚´ì¼", "ëª¨ë ˆ", "ë‹¤ìŒ ì£¼" ë“± ìƒëŒ€ í‘œí˜„ì€ ì˜¤ëŠ˜ ë‚ ì§œ({today})ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•´ì„í•´ YYYY-MM-DDë¡œ ë³€í™˜

ë°˜ë“œì‹œ ìœ„ JSON í˜•ì‹ë§Œ ë°˜í™˜í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

ë¬¸ì¥: "{message}"
"""

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
        )

        raw_reply = response.choices[0].message.content
        cleaned = self._clean_json_output(raw_reply)

        try:
            parsed = json.loads(cleaned)
        except json.JSONDecodeError:
            parsed = {"events": []}

        usage = response.usage.to_dict() if hasattr(response, "usage") else {}

        return parsed, usage

    def generate_simple_reply(self, user_input: str) -> str:
        messages = self.conversation_history + [{"role": "user", "content": user_input}]

        response = self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê°„ë‹¨í•˜ê³  ë”°ëœ»í•˜ê²Œ ëŒ€ë‹µí•´ì£¼ëŠ” ëŒ€í™” íŒŒíŠ¸ë„ˆì•¼."},
                *messages
            ],
            temperature=0.7,
        )

        reply = response.choices[0].message.content.strip()

        self.conversation_history.append({"role": "user", "content": user_input})
        self.conversation_history.append({"role": "assistant", "content": reply})

        return reply

    def run_pipeline(self, message: str) -> dict | str:
        print(f"nğŸ“¥ ì…ë ¥ ë©”ì‹œì§€: {message}")

        has_intent, _ = self.has_date(message)
        if not has_intent:
            return self.generate_simple_reply(message)

        has_info, _ = self.has_date_info(message)
        if has_info:
            schedule, _ = self.extract_schedule(message)
            return schedule
        else:
            try:
                raw_json = self.crawlr.extraction(message)

                # âœ… í¬ë¡¤ë§ ê¸°ë°˜ ì¶”ì¶œ ê²°ê³¼ ì¶œë ¥
                print("nğŸ“¡ í¬ë¡¤ë§ ê¸°ë°˜ ì¼ì • ì¶”ì¶œ ê²°ê³¼:")
                print(json.dumps(raw_json, indent=2, ensure_ascii=False))

                if isinstance(raw_json, str):
                    parsed = json.loads(raw_json)
                elif isinstance(raw_json, dict):
                    parsed = raw_json
                else:
                    parsed = {"events": []}

                return parsed

            except Exception as e:
                print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
                return {"events": []}


if __name__ == "__main__":
    detector = GPTDateDetector()
    while True:
        msg = input("n[ì…ë ¥] ")
        if msg.lower() == "exit":
            break
        result = detector.run_pipeline(msg)
        print(f"ğŸ“¤ ê²°ê³¼: {result}")
