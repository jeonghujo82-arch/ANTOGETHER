import requests
from bs4 import BeautifulSoup
import os
from dotenv import load_dotenv

# .envì—ì„œ API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸°
# Environment variables are now loaded globally in backend_new.py


class NaverCrawler:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ë° ë³¸ë¬¸ ì¶”ì¶œ ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” í´ë˜ìŠ¤
    """
    def __init__(self):
        self.base_url = "https://openapi.naver.com/v1/search/news.json"
        self.headers = {
            "X-Naver-Client-Id": os.getenv("NAVER_CLIENT_ID"),
            "X-Naver-Client-Secret": os.getenv("NAVER_CLIENT_SECRET")
        }

    def search(self, query, display=5):  # âœ… display ê¸°ë³¸ê°’ì„ 5ê°œë¡œ ì¦ê°€
        params = {
            "query": query,
            "display": display,
            "sort": "date"
        }

        try:
            res = requests.get(self.base_url, headers=self.headers, params=params)
            res.raise_for_status()
            items = res.json().get("items", [])

            results = []
            print("ğŸ” ê²€ìƒ‰ ê²°ê³¼ ìˆ˜:", len(items))
            for item in items:
                title_html = item.get("title", "")
                title_clean = BeautifulSoup(title_html, "html.parser").get_text(" ", strip=True)

                print(f"ğŸ“„ ì œëª©: {title_clean}, ë§í¬: {item['link']}")  # âœ… ì œëª©/ë§í¬ ì¶œë ¥

                results.append({
                    "title": title_clean,
                    "link": item["link"]
                })

            return results
        except Exception as e:
            print("âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨:", e)
            return []

    def extract_text(self, url):
        try:
            headers = {"User-Agent": "Mozilla/5.0"}
            res = requests.get(url, headers=headers, timeout=5)
            res.encoding = res.apparent_encoding
            soup = BeautifulSoup(res.text, "html.parser")

            naver_main = soup.select_one("div#newsct_article")
            if naver_main:
                text = naver_main.get_text(" ", strip=True)
            else:
                candidates = [
                    soup.find("article"),
                    soup.find("div", class_="content"),
                    soup.find("main"),
                    soup.find("body")
                ]

                text = ""
                for c in candidates:
                    if c and c.get_text(strip=True):
                        text = c.get_text(" ", strip=True)
                        break

            if not text:
                text = "ë³¸ë¬¸ ì—†ìŒ"

            print(f"ğŸ“ ë³¸ë¬¸ ê¸¸ì´: {len(text)}")
            print(f"ğŸ“ ë³¸ë¬¸ ë‚´ìš© ì•ë¶€ë¶„: {text[:200]}...")  # âœ… ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥
            return text
        except Exception as e:
            print("âŒ ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨:", e)
            return "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"
